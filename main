#!/usr/bin/env python3
import datetime
import sys
import os
import requests
import json
import time
import sys

DEBUG=False
defaultstop = 100111
maxconn = 4 # led-panel hat maximal Platz für 4 Verbindungen
defaultvia = 100000 # show only via Aachen Bushof

start = 1
baseurl		= "http://ivu.aseag.de/interfaces/ura/{}"
url_l		= "location"
url_i		= "instant_V2"
returnlist	= "StopPointName,StopID,StopPointState,StopPointIndicator,Latitude,Longitude,LineID,LineName,DirectionID,DestinationName,DestinationText,VehicleId,TripId,EstimatedTime,BaseVersion"
usage		= "Usage: don't"

totime = 0

if len(sys.argv) == 1 and defaultstop == 0:
	print(usage.format(__file__))
	exit(0)

def debug(text):
	if DEBUG == True:
		print(text)

def unix_epoch_to_datetime(epoch_ms):
	return datetime.datetime.fromtimestamp(epoch_ms * (10**(-3)))

def unix_epoch_to_date(epoch_ms):
	return unix_epoch_to_datetime(epoch_ms).strftime('%Y-%m-%d %H:%M:%S')

def unix_epoch_to_time(epoch_ms):
	return unix_epoch_to_datetime(epoch_ms).strftime('%H:%M:%S')

def unix_epoch_from_now():
	return int(datetime.datetime.now().timestamp() * 1000)

def datetime_timediff(dt):
	diff = max(dt - datetime.datetime.now(), datetime.datetime.now() - dt) # bugfix against weird underflow bug
	if diff.seconds//60 > 99:
		return '++'
	else:
		return diff.seconds//60

def get_stoppoint(name):
	parameter = {'searchString': name, 'maxResults': 10, 'searchTypes': 'STOPPOINT'}
	request = requests.get(baseurl.format(url_l), params=parameter)
	if request.status_code != 200:
		raise Exception
	if request.headers['content-type'] != 'application/json;charset=UTF-8':
		raise Exception
	data = request.json()
	if data['resultCount'] == 0:
		debug("No result for stop name {}".format(name))
		return {}
	elif data['resultCount'] > 1:
		print("More than one result for stop name {}:".format(name))
		print("ID\tName")
		for elem in data['resultList']:
			print("{}\t{}".format(elem['stopPointId'], elem['stopPointName']))
		exit(0)
		# this might be broken anyway
		#return dict((elem['stopPointId'] = elem['stopPointName']) for elem in data['resultList'])

	else:
		debug("ID\tName")
		debug("{}\t{}".format(data['resultList'][0]['stopPointId'], data['resultList'][0]['stopPointName']))
		return {data['resultList'][0]['stopPointId']: data['resultList'][0]['stopPointName']}

def parsejson(data, encoding):
	output = []
	for line in data.splitlines():
		linelist = json.loads(line)
		if (linelist[0] == 1 and include_trip(linelist[13])):
			output.append((linelist[14],linelist[8],linelist[11]))
	output.sort(key=lambda tup: tup[0])
	return output

def parsetrip(data, encoding):
	output = []
	for line in data.splitlines():
		linelist = json.loads(line)
		if (linelist[0] == 1 and (int(linelist[2]) == defaultstop or int(linelist[2]) == defaultvia)):
			output.append((linelist[14],linelist[2]))
	output.sort(key=lambda tup: tup[0])
	if len(output) != 2:
		return False
	if int(output[0][1]) == defaultstop and int(output[1][1]) == defaultvia:
		return True
	elif int(output[1][1]) == defaultstop and int(output[0][1]) == defaultvia:
		return False
	else:
		# lol undefined behaviour
		raise Exception

# See: http://stackoverflow.com/questions/480214/how-do-you-remove-duplicates-from-a-list-in-python-whilst-preserving-order
def deduplication(data):
	jsondata = data
	seen = set()
	seen_add = seen.add
	jsondata = [x for x in jsondata if not (x in seen or seen_add(x))]
	return jsondata

def tsfilter(ts, totime): # Todo: schöner machen
	if totime == 0:
		return (unix_epoch_to_datetime(ts) >= datetime.datetime.now() + datetime.timedelta(minutes = 3))
	else:
		return (unix_epoch_to_datetime(ts) >= datetime.datetime.now() - datetime.timedelta(minutes = 5)) and (unix_epoch_to_datetime(ts) <= datetime.datetime.now() + datetime.timedelta(minutes = totime))

def get_stopdata(stop_point_id):
	parameter = {'ReturnList': returnlist, 'StopID': stop_point_id}
	request = requests.get(baseurl.format(url_i), params = parameter)
	if request.status_code != 200:
		raise Exception
	if request.headers['content-type'] != 'application/json;charset=UTF-8':
		raise Exception
	data = deduplication(parsejson(request.text, request.encoding))
	return data

# TODO: Get the destination's stop point data and compare trip ids instead
def include_trip(tripid):
	parameter = {'ReturnList': returnlist, 'TripID': tripid}
	request = requests.get(baseurl.format(url_i), params = parameter)
	if request.status_code != 200:
		raise Exception
	if request.headers['content-type'] != 'application/json;charset=UTF-8':
		raise Exception
	include = parsetrip(request.text, request.encoding)
	return include

def parseargv(): #parses argv, returns StopID and LineID
	query_stop = [defaultstop]
	argc = len(sys.argv)
	return (query_stop, query_ids)

def output():
	global start
	output = get_stopdata(defaultstop)
	counter = 0
	if not start:
		sys.stdout.write("\n")
	start = 0
	for line in output:
		if counter == maxconn:
			break
		if tsfilter(line[0], totime):
			counter += 1
			sys.stdout.write("{:>2} {:>3} {}".format(datetime_timediff(unix_epoch_to_datetime(line[0])), line[1], line[2]))
			sys.stdout.write("\n")
			sys.stdout.flush()
	while counter < maxconn:
		print()
		counter -= 1

while True:
	try:
		output()
	except:
		pass
	time.sleep(20)


